{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Congestion: A Comparison of Machine Learning Models in a Time-Series Scenario\n",
    "\n",
    "Vehicular traffic and its management can be a challenge and is a pressing issue for most of our modern highways and road networks. We run the world on our roads and highways. And we can only imagine a world without such networks. As cities expand and people specifically in the developing world move to urban areas for opportunities and livelihood, the exponential increase in vehicle ownership and thereby the number of active automobiles has posed challenges for civic and government authorities and road related mishaps also increase in parallel. While many developed countries are far from facing the brunt of population pressures and hence a lower number vehicular ownership, in other parts such as China and India the scenario seems altogether different. This is not to mention that even the most well laid out road can record accidents and traffic mismanagement. In such circumstances, machine learning can predict what the traffic would be at what hour and how it could be managed at that point. So let's see how.\n",
    "\n",
    "Below presented is a typical time-series dataset with hurly timestamps, starting from 1960s all the way to present day. The problem might seem tricial but as we proceed, things become clearer that data preprocessing and deep exploration are compulsory steps before utilising learning methods. This is because of the simple principle - if you do not know the data well you cannot predict on it well.\n",
    "\n",
    "This analysi can be used for several purposes; from learning some of the nuances of undertaking typical time-series projects to simple reference material for those looking to freshen up their knowledge in  time-series work flows. This dataset also  also happens to be hosted at one of the [hackathons][1] and is also available at [kaggle][2] free for public use.\n",
    "\n",
    "With all that said, let's define our goals and dive straight in. \n",
    "\n",
    "[1]: https://www.hackerearth.com/challenges/competitive/IIT-Madras-Sangam-ML-Hackathon-2019/\n",
    "[2]: https://www.kaggle.com/rohith203/traffic-volume-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives of this Notebook\n",
    "\n",
    "At the end of the project, we'll learn:\n",
    "\n",
    "- How time-series datasets are preprocessed, taking into consideration similar techniques used in supervised analysis.\n",
    "- Best practices for deciding time series hyper-parameters (p, d and q).\n",
    "- Use cross validation to compare standard machine learning models.\n",
    "- Use cross validation to compare time series parameters.\n",
    "\n",
    "Libraries used are mostly standard scientific modules such as `statsmodels` and `scikit-learn`. Additional libraries wherever used will be described briefly. I personally like to use only the required modules and make the most of out of them.\n",
    "\n",
    "# Data Loading and Exploration\n",
    "\n",
    "We start off with loading our data and the relevant modules. The data is in standard .csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from numpy import log\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from xgboost import XGBRegressor, XGBRFRegressor\n",
    "from yellowbrick.regressor import residuals_plot, prediction_error\n",
    "from yellowbrick.features import rank2d, rank1d\n",
    "from yellowbrick.model_selection import RFECV, ValidationCurve, LearningCurve\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, ElasticNetCV, SGDRegressor, PassiveAggressiveRegressor, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "from warnings import filterwarnings\n",
    "from matplotlib.pylab import rcParams\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from seaborn import catplot\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import pandas_profiling\n",
    "import statsmodels.api as sm\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "register_matplotlib_converters()\n",
    "filterwarnings(\"ignore\")\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "# rcParams['figure.figsize'] = 10, 8\n",
    "plt.ion()\n",
    "np.random.seed(1000)\n",
    "print(\"\\nEnvironment is ready.\")\n",
    "\n",
    "main_data = dd.read_csv(\"Train.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
